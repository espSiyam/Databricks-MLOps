{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c59f3d11-d42d-43e7-8d4d-64bbbecc9fc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import * \n",
    "from pyspark.ml.feature import StringIndexer, Word2Vec, VectorAssembler\n",
    "from pyspark.ml.linalg import DenseVector, VectorUDT\n",
    "from pyspark.sql.types import ArrayType, FloatType\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "06d9412d-d1e2-4094-b825-6336318dadef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "telco_path = \"sdd_dev.sohag_test.telco_customer_churn\"\n",
    "telco_df = spark.read.table(telco_path)\n",
    "display(telco_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2cc673cf-ad29-4a83-a849-46a6147440c5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Processing the dataset\n",
    "\n",
    "## Handing missing values\n",
    "* NULL values might be stored as \"null\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "599e0001-f3a9-4c51-baf1-2ccb128c8d94",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "bad_vals = [\"null\", \"\"]          # add more literals if you find them\n",
    "for c in telco_df.columns:\n",
    "    telco_df = telco_df.withColumn(\n",
    "        c,\n",
    "        when(trim(col(c)).isin(bad_vals), None)      # \"null\", \"\", \"   \"\n",
    "        .otherwise(col(c))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0e2b3f8c-a955-431c-8928-e0c3376e2d54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2️⃣  Cast columns that should be numeric ------------------------------------\n",
    "#    – add any other numeric columns you have\n",
    "numeric_cols = [\"SeniorCitizen\", \"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "for c in numeric_cols:\n",
    "    telco_df = telco_df.withColumn(c, col(c).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1b380d4f-2cb2-42ff-9e20-461ca2dace08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# # 3️⃣  Optional: drop any rows that still contain nulls -----------------------\n",
    "# telco_df = telco_df.dropna() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b27242ac-4d52-4823-b7f3-55ed976b93b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Converting datatype\n",
    "* SeniorCitizen should be Boolean.\n",
    "* TotalCharges should be double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f53b0b1-c9d7-4474-9ba5-56a9ad15059d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "telco_df = telco_df.withColumn(\"SeniorCitizen\", when(col(\"SeniorCitizen\")==1, True).otherwise(False))\n",
    "\n",
    "display(telco_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1501b8bd-4533-4817-9f83-3bd7c31a8f26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Splitting the dataset into trianing and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "141934a7-cf6e-4c54-8611-2396c9283269",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = telco_df.randomSplit([.8, .2], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9ca602d8-8a42-40fc-b8d3-cee8d1e447d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Transforming the dataset\n",
    "* Coverting Integer and Boolena columns to double"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5bddf09-98e0-49c0-ab16-2d5f611ddf1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of integer and boolean columns\n",
    "integer_cols = [column.name for column in train_df.schema.fields if (column.dataType == IntegerType() or column.dataType == BooleanType())]\n",
    "print(integer_cols)\n",
    "\n",
    "for column in integer_cols:\n",
    "    train_df = train_df.withColumn(column, col(column).cast(\"double\"))\n",
    "    test_df = test_df.withColumn(column, col(column).cast(\"double\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "559783a2-09a3-4a69-924b-9bc0977bf5a1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Get a list of numeric columns\n",
    "num_cols = [c.name for c in train_df.schema.fields if c.dataType == DoubleType()]\n",
    "print(num_cols)\n",
    "\n",
    "# Dictionary of {column: missing_count} for columns with missing values\n",
    "num_missing_cols = [\n",
    "    c for c in num_cols\n",
    "    if train_df.filter(col(c).isNull()).count() > 0\n",
    "]\n",
    "print(num_missing_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "98aa6403-f501-4312-8b31-7e4c8a990fd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1. Identify string columns\n",
    "string_cols = [c.name for c in train_df.schema.fields if isinstance(c.dataType, StringType)]\n",
    "\n",
    "# 2. Count missing values in string columns\n",
    "string_missing_values_logic = [\n",
    "    count(when(col(column).isNull(), column)).alias(column) for column in string_cols\n",
    "]\n",
    "row_dict_string = train_df.select(string_missing_values_logic).first().asDict()\n",
    "string_missing_cols = [column for column in row_dict_string if row_dict_string[column] > 0]\n",
    "\n",
    "print(f\"String columns with missing values: {string_missing_cols}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8e95f38d-a96a-40b9-967f-75b6e8d4fdd9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "# Creating a Feature Engineering Pipeline (Spark ML pipeline)\n",
    "* Generate embeffing for categoriacal features\n",
    "* Handling missing values\n",
    "* Standardizing numerical feature\n",
    "* Combining features into a Final vector\n",
    "* Encapsulating steps into a pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ee450e86-c82f-43c6-9e5f-3d105d3c6a6c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Pipeline - Feature Engineering and Embedding",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
